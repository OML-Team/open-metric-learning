postfix: metric_learning

seed: 42
precision: 16
accelerator: gpu
devices: 2

dataframe_name: df.csv
dataset_root: /nydl/data/DeepFashion_InShop/
logs_root: /nydl/logs/8feb/InShop/
logs_folder: ${now:%Y-%m-%d_%H-%M-%S}_${postfix}

num_workers: 20
cache_size: 0

transforms_train:
  name: augs_hypvit_torch
  args:
    im_size: 224

transforms_val:
  name: norm_resize_hypvit_torch
  args:
    im_size: 224
    crop_size: 224

sampler:
  name: category_balance
  args:
    n_labels: 30
    n_instances: 4
    n_categories: 5
    resample_labels: True
    weight_categories: True

bs_val: 256
max_epochs: 10000
valid_period: 1

metric_args:
  metrics_to_exclude_from_visualization: [cmc,]
  cmc_top_k: [1, 5]
  map_top_k: [5]
  fmr_vals: []  # Since InShop is a big dataset you should be careful with increasing of the memory footprint, which is needed to calculate fmr
  pfc_variance: []
  return_only_main_category: True
  visualize_only_main_category: True

log_images: False

metric_for_checkpointing: OVERALL/cmc/1

model:
  name: vit
  args:
    normalise_features: True
    use_multi_scale: False
    weights: vits16_dino
    arch: vits16

criterion:
  name: triplet_with_miner
  args:
    need_logs: True
    margin: 0.15
    reduction: mean
    miner:
      name: hard_triplets
      args: {}

optimizer:
  name: adamw
  args:
    lr: 1e-5


scheduling: null


# To use neptune you should also specify NEPTUNE_API_TOKEN in
# .env file or via `export NEPTUNE_API_TOKEN=...`
neptune_project: null


hydra_dir: ${logs_root}/${logs_folder}/

tags:
  - ${postfix}
  - deepfashion

hydra:
  run:
    dir: ${hydra_dir}
  searchpath:
   - pkg://oml.configs
