{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from oml.datasets.base import BaseDataset\n",
    "from oml.models.vit.vit import ViTExtractor\n",
    "from oml.transforms.images.albumentations.transforms import get_normalisation_resize_albu\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.max_rows', 330)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = Path(\"/nydl/data/DeepFashion_InShop/\")\n",
    "batch_size = 1024\n",
    "weights = \"vits16_dino\"\n",
    "\n",
    "df = pd.read_csv(dataset_root / \"df_no_bboxes.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = BaseDataset(df=df, transform=get_normalisation_resize_albu(im_size=224))\n",
    "# model = ViTExtractor(weights, arch=\"vits16\", normalise_features=False).eval().cuda()\n",
    "# train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# embeddings = torch.zeros((len(df), model.feat_dim))\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for i, batch in enumerate(tqdm(train_loader)):\n",
    "#         embs = model(batch[\"input_tensors\"].cuda()).detach().cpu()\n",
    "#         ia = i * batch_size\n",
    "#         ib = min(len(embeddings), (i + 1) * batch_size)\n",
    "#         embeddings[ia:ib, :] = embs\n",
    "\n",
    "        \n",
    "# torch.save(embeddings, dataset_root / f\"embeddings_{weights}.pkl\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.load(dataset_root / f\"embeddings_{weights}.pkl\")\n",
    "dataset = TensorDataset(embeddings, torch.tensor(df[\"label\"].to_numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
