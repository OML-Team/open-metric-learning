{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-opposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/ashabanov/code/metric_learning/open-metric-learning\")\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from oml.datasets.base import BaseDataset\n",
    "from oml.models.vit.vit import ViTExtractor\n",
    "from oml.transforms.images.torchvision.transforms import get_normalisation_resize_hypvit\n",
    "from oml.transforms.images.utils import get_im_reader_for_transforms\n",
    "from oml.metrics.embeddings import EmbeddingMetrics\n",
    "from oml.postprocessors.pairwise_embeddings import PairwiseEmbeddingsPostprocessor\n",
    "from oml.samplers.balance import BalanceSampler\n",
    "from oml.miners.inbatch_all_tri import AllTripletsMiner\n",
    "from oml.utils.misc_torch import elementwise_dist\n",
    "\n",
    "from source import TensorsWithLabels\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.max_rows', 330)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = Path(\"/nydl/data/Stanford_Online_Products/\")\n",
    "weights = \"vits16_sop\"\n",
    "\n",
    "if False:  # save features\n",
    "    batch_size = 1024\n",
    "\n",
    "    df = pd.read_csv(dataset_root / \"df.csv\")\n",
    "\n",
    "    transform = get_normalisation_resize_hypvit(im_size=224, crop_size=224)\n",
    "    im_reader = get_im_reader_for_transforms(transform)\n",
    "\n",
    "    dataset = BaseDataset(df=df, transform=transform, f_imread=im_reader)\n",
    "    model = ViTExtractor(weights, arch=weights.split(\"_\")[0], normalise_features=True).eval().cuda()\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=20)\n",
    "\n",
    "    embeddings = torch.zeros((len(df), model.feat_dim))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(train_loader)):\n",
    "            embs = model(batch[\"input_tensors\"].cuda()).detach().cpu()\n",
    "            ia = i * batch_size\n",
    "            ib = min(len(embeddings), (i + 1) * batch_size)\n",
    "            embeddings[ia:ib, :] = embs\n",
    "\n",
    "    torch.save(embeddings, dataset_root / f\"embeddings_{weights}.pkl\")\n",
    "    \n",
    "    \n",
    "\n",
    "def get_datasets():\n",
    "    embeddings = torch.load(dataset_root / f\"embeddings_{weights}.pkl\")\n",
    "    df = pd.read_csv(dataset_root / \"df.csv\")\n",
    "    train_mask = df[\"split\"] == \"train\"\n",
    "    \n",
    "    emb_train = embeddings[train_mask]\n",
    "    emb_val = embeddings[~train_mask]\n",
    "    \n",
    "    df_train = df[train_mask]\n",
    "    df_train.reset_index(inplace=True)\n",
    "    \n",
    "    df_val = df[~train_mask]\n",
    "    df_val.reset_index(inplace=True)\n",
    "\n",
    "    return emb_train, emb_val, df_train, df_val\n",
    "\n",
    "\n",
    "emb_train, emb_val, df_train, df_val = get_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllPairsMiner:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.miner = AllTripletsMiner()\n",
    "        \n",
    "    def sample(self, features, labels):\n",
    "        ii_a, ii_p, ii_n = self.miner._sample(None, labels=labels)\n",
    "        ii_a, ii_p, ii_n = zip(*sorted(list(set(zip(ii_a, ii_p, ii_n)))))\n",
    "        \n",
    "        # leave only unique pairs\n",
    "        ii_a, ii_p = zip(*sorted(list(set(tuple(zip(ii_a, ii_p))))))\n",
    "        ii_a, ii_n = zip(*sorted(list(set(tuple(zip(ii_a, ii_n))))))\n",
    "        \n",
    "        gt_distance = torch.zeros(2 * len(ii_a)).bool()\n",
    "        gt_distance[len(ii_a):] = True\n",
    "                \n",
    "        return features[[*ii_a, *ii_a]], features[[*ii_p, *ii_n]], gt_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Siamese(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, feat_dim: int, identity_init: bool):\n",
    "        super(Siamese, self).__init__()\n",
    "        self.feat_dim = feat_dim\n",
    "\n",
    "        self.proj1 = torch.nn.Sequential(*[\n",
    "            torch.nn.Linear(feat_dim, feat_dim, bias=True),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(feat_dim, 1),\n",
    "        ])\n",
    "        \n",
    "        self.proj2 = torch.nn.Sequential(*[\n",
    "            torch.nn.Linear(feat_dim, feat_dim, bias=True),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(feat_dim, 1),\n",
    "        ])\n",
    "        \n",
    "        self.proj12 = torch.nn.Sequential(*[\n",
    "            torch.nn.Linear(2 * feat_dim, 2 * feat_dim, bias=True),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(2 * feat_dim, 1),\n",
    "        ])\n",
    "        \n",
    "#         self.w = torch.nn.Parameter(data=torch.tensor([0.0]))\n",
    "        \n",
    "#         if identity_init:\n",
    "#             ini_dict = {\"weight\": torch.eye(feat_dim), \"bias\": torch.zeros(feat_dim)}\n",
    "#             self.proj1.load_state_dict(ini_dict)\n",
    "#             self.proj2.load_state_dict(ini_dict)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        d0 = 1 - (x1 * x2).sum(dim=1)\n",
    "        \n",
    "        d1 = self.proj1(x1)\n",
    "        d2 = self.proj2(x2) \n",
    "        d12 = self.proj12(torch.cat([x1, x2], dim=1))\n",
    "        \n",
    "        return d0 + d1 + d2 + d12\n",
    "    \n",
    "    \n",
    "y = Siamese(3, True)(torch.tensor([[0.0, 1, 0]]), torch.tensor([[0.0, 0, 1]]))\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-publicity",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "model = Siamese(feat_dim=384, identity_init=True)\n",
    "model.cuda().train()\n",
    "\n",
    "dataset = TensorsWithLabels(df_train, emb_train)\n",
    "\n",
    "n_labels, n_instances = 2, 2\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    batch_sampler=BalanceSampler(labels=dataset.get_labels(), n_labels=n_labels, n_instances=n_instances),\n",
    "    dataset=dataset\n",
    ")\n",
    "\n",
    "b = next(iter(loader))\n",
    "batches = [b] * 900\n",
    "\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-3)\n",
    "\n",
    "pairs_miner = AllPairsMiner()\n",
    "criterion = torch.nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "losses = []\n",
    "acc = []\n",
    "\n",
    "for _ in range(1):\n",
    "    tqdm_loader = tqdm(batches)\n",
    "    for batch in tqdm_loader:\n",
    "        x1, x2, gt_dist = pairs_miner.sample(batch[\"input_tensors\"], batch[\"labels\"])\n",
    "        x1, x2, gt_dist = x1.cuda(), x2.cuda(), gt_dist.cuda()\n",
    "\n",
    "        pred_dist = model(x1=x1, x2=x2)   \n",
    "        loss = criterion(pred_dist, gt_dist.float())\n",
    "                \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # logs\n",
    "        accuracy = ((pred_dist > 0.5) == gt_dist).float().mean().item()\n",
    "        tqdm_loader.set_postfix({\"acc\": accuracy, \"loss\": loss.item()})\n",
    "        losses.append(loss.item())\n",
    "        acc.append(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()\n",
    "plt.plot(acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation with postprocessing\n",
    "# model = Siamese(384, True).cuda() # <-- note\n",
    "\n",
    "processor = PairwiseEmbeddingsPostprocessor(model, top_n=5)\n",
    "\n",
    "calculator = EmbeddingMetrics(\n",
    "    cmc_top_k=(1, 5, 10),\n",
    "    postprocessor=processor\n",
    ")\n",
    "calculator.setup(len(df_val))\n",
    "calculator.update_data({\n",
    "    \"embeddings\": emb_val,\n",
    "    \"is_query\": torch.tensor(df_val[\"is_query\"]).bool(),\n",
    "    \"is_gallery\": torch.tensor(df_val[\"is_gallery\"]).bool(),\n",
    "    \"labels\": torch.tensor(df_val[\"label\"]).long()\n",
    "})\n",
    "metrics = calculator.compute_metrics();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-liberty",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
