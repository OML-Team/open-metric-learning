{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-opposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/ashabanov/code/metric_learning/open-metric-learning\")\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from oml.datasets.base import BaseDataset\n",
    "from oml.models.vit.vit import ViTExtractor\n",
    "from oml.transforms.images.torchvision.transforms import get_normalisation_resize_hypvit\n",
    "from oml.transforms.images.utils import get_im_reader_for_transforms\n",
    "from oml.metrics.embeddings import EmbeddingMetrics\n",
    "from oml.postprocessors.pairwise_embeddings import PairwiseEmbeddingsPostprocessor\n",
    "from oml.samplers.balance import BalanceSampler\n",
    "from oml.miners.inbatch_all_tri import AllTripletsMiner\n",
    "\n",
    "from source import TensorsWithLabels\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.max_rows', 330)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = Path(\"/nydl/data/Stanford_Online_Products/\")\n",
    "weights = \"vits16_sop\"\n",
    "\n",
    "if False:  # save features\n",
    "    batch_size = 1024\n",
    "\n",
    "    df = pd.read_csv(dataset_root / \"df.csv\")\n",
    "\n",
    "    transform = get_normalisation_resize_hypvit(im_size=224, crop_size=224)\n",
    "    im_reader = get_im_reader_for_transforms(transform)\n",
    "\n",
    "    dataset = BaseDataset(df=df, transform=transform, f_imread=im_reader)\n",
    "    model = ViTExtractor(weights, arch=weights.split(\"_\")[0], normalise_features=True).eval().cuda()\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=20)\n",
    "\n",
    "    embeddings = torch.zeros((len(df), model.feat_dim))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(train_loader)):\n",
    "            embs = model(batch[\"input_tensors\"].cuda()).detach().cpu()\n",
    "            ia = i * batch_size\n",
    "            ib = min(len(embeddings), (i + 1) * batch_size)\n",
    "            embeddings[ia:ib, :] = embs\n",
    "\n",
    "    torch.save(embeddings, dataset_root / f\"embeddings_{weights}.pkl\")\n",
    "    \n",
    "    \n",
    "\n",
    "def get_datasets():\n",
    "    embeddings = torch.load(dataset_root / f\"embeddings_{weights}.pkl\")\n",
    "    df = pd.read_csv(dataset_root / \"df.csv\")\n",
    "    train_mask = df[\"split\"] == \"train\"\n",
    "    \n",
    "    emb_train = embeddings[train_mask]\n",
    "    emb_val = embeddings[~train_mask]\n",
    "    \n",
    "    df_train = df[train_mask]\n",
    "    df_train.reset_index(inplace=True)\n",
    "    \n",
    "    df_val = df[~train_mask]\n",
    "    df_val.reset_index(inplace=True)\n",
    "\n",
    "    return emb_train, emb_val, df_train, df_val\n",
    "\n",
    "\n",
    "emb_train, emb_val, df_train, df_val = get_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-bubble",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllPairsMiner():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.miner = AllTripletsMiner()\n",
    "        \n",
    "    def sample(self, features, labels):\n",
    "        ii_a, ii_p, ii_n = self.miner._sample(None, labels=labels)\n",
    "                \n",
    "        is_same = torch.ones(2 * len(ii_a)).bool()\n",
    "        is_same[len(ii_a):] = False\n",
    "        \n",
    "        return features[[*ii_a, *ii_a]], features[[*ii_p, *ii_n]], is_same\n",
    "\n",
    "    \n",
    "class Siamese:\n",
    "\n",
    "    def __init__(self, feat_dim: int, identity_init: bool):\n",
    "        super(Siamese, self).__init__()\n",
    "        self.feat_dim = feat_dim\n",
    "\n",
    "        self.proj1 = torch.nn.Linear(in_features=feat_dim, out_features=feat_dim, bias=False)\n",
    "        self.proj2 = torch.nn.Linear(in_features=feat_dim, out_features=feat_dim, bias=False)\n",
    "\n",
    "        if identity_init:\n",
    "            self.proj1.load_state_dict({\"weight\": torch.eye(feat_dim)})\n",
    "            self.proj2.load_state_dict({\"weight\": torch.eye(feat_dim)})\n",
    "\n",
    "    def forward(self, x1: Tensor, x2: Tensor) -> Tensor:\n",
    "        x1 = self.proj1(x1)\n",
    "        x2 = self.proj2(x2)\n",
    "        y = elementwise_dist(x1, x2, p=2)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "model = Siamese(feat_dim=384, identity_init=True)\n",
    "model.cuda()\n",
    "\n",
    "dataset = TensorsWithLabels(df_train, emb_train)\n",
    "\n",
    "n_labels, n_instances = 50, 4\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    batch_sampler=BalanceSampler(labels=dataset.get_labels(), n_labels=n_labels, n_instances=n_instances),\n",
    "    dataset=dataset\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-5)\n",
    "\n",
    "pairs_miner = AllPairsMiner()\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "\n",
    "losses = []\n",
    "\n",
    "for _ in range(5):\n",
    "    for batch in tqdm(loader):\n",
    "        x1, x2, gt = pairs_miner.sample(batch[\"input_tensors\"], batch[\"labels\"])\n",
    "        pred = model(x1=x1.cuda(), x2=x2.cuda())\n",
    "        pred = pred / 2 # scale l2\n",
    "        loss = criterion(pred, gt.float().cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        losses.append(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation with postprocessing\n",
    "processor = PairwiseEmbeddingsPostprocessor(model, top_n=5)\n",
    "\n",
    "calculator = EmbeddingMetrics(\n",
    "    cmc_top_k=(1, 5, 10),\n",
    "    postprocessor=processor\n",
    ")\n",
    "calculator.setup(len(df_val))\n",
    "calculator.update_data({\n",
    "    \"embeddings\": emb_val,\n",
    "    \"is_query\": torch.tensor(df_val[\"is_query\"]).bool(),\n",
    "    \"is_gallery\": torch.tensor(df_val[\"is_gallery\"]).bool(),\n",
    "    \"labels\": torch.tensor(df_val[\"label\"]).long()\n",
    "})\n",
    "metrics = calculator.compute_metrics();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-merchandise",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
