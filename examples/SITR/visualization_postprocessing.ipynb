{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/nydl/code/open-metric-learning/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from oml.lightning.entrypoints.validate import pl_val\n",
    "from oml.lightning.callbacks.metric import MetricValCallback\n",
    "from oml.const import MOCK_DATASET_PATH\n",
    "from oml.utils.download_mock_dataset import download_mock_dataset\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.max_rows', 330)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8b5d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights: /home/daloro/python_projects/open-metric-learning/embedder.ckpt\n",
    "#/home/daloro/python_projects/open-metric-learning/postprocessor.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = f\"\"\"\n",
    "    dataset_root: /home/daloro/data/DeepFashion_InShop/\n",
    "    dataframe_name: df.csv\n",
    "    logs_root: /home/daloro/logs\n",
    "    bs_val: 224\n",
    "    num_workers: 12\n",
    "    \n",
    "    transforms_val:\n",
    "      name: norm_resize_hypvit_torch\n",
    "      args:\n",
    "        im_size: 224\n",
    "        crop_size: 224\n",
    "\n",
    "    model:\n",
    "      name: vit\n",
    "      args:\n",
    "        arch: vits16\n",
    "        normalise_features: False\n",
    "        use_multi_scale: False\n",
    "        weights: /home/daloro/Downloads/embedder_inshop.ckpt\n",
    "\n",
    "    metric_args:\n",
    "      cmc_top_k: [1, 5, 10]\n",
    "      map_top_k: [5, 10]\n",
    "      return_only_main_category: True\n",
    "      \n",
    "      \n",
    "    accelerator: gpu\n",
    "    devices: 1\n",
    "  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer, ret_dict = pl_val(yaml.load(cfg, Loader=yaml.Loader));\n",
    "clb_metric = [x for x in trainer.callbacks if isinstance(x, MetricValCallback)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530c6abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clb_metric = [x for x in trainer.callbacks if isinstance(x, MetricValCallback)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fa239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.load(\"/home/daloro/Downloads/post_inshop.ckpt\", map_location=\"cpu\")[\"state_dict\"]\n",
    "\n",
    "kvs = list(y.items())\n",
    "for k, v in kvs:\n",
    "    if k.startswith(\"model_pairwise\"):\n",
    "        del y[k]\n",
    "        \n",
    "torch.save({\"state_dict\": y}, \"/home/daloro/Downloads/post_inshop.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-holiday",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_p =  cfg + f\"\"\"\n",
    "    postprocessor:\n",
    "      name: pairwise_images\n",
    "      args:\n",
    "        top_n: 9\n",
    "        pairwise_model:\n",
    "          name: concat_siamese\n",
    "          args:\n",
    "            mlp_hidden_dims: [192]\n",
    "            weights: /home/daloro/Downloads/post_inshop.ckpt\n",
    "            extractor:\n",
    "              name: vit\n",
    "              args:\n",
    "                arch: vits16\n",
    "                normalise_features: False\n",
    "                use_multi_scale: False\n",
    "                weights: null\n",
    "        transforms:\n",
    "          name: norm_resize_hypvit_torch\n",
    "          args:\n",
    "            im_size: 224\n",
    "            crop_size: 224\n",
    "        num_workers: 12\n",
    "        batch_size: 224\n",
    "        verbose: True\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-basin",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "st = time.perf_counter()\n",
    "trainer_p, ret_dict_p = pl_val(yaml.load(cfg_p, Loader=yaml.Loader));\n",
    "et = time.perf_counter()\n",
    "clb_metric_p = [x for x in trainer_p.callbacks if isinstance(x, MetricValCallback)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640273d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(et - st) / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70b3e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "(60 * 3 + 8) / (5 * len(clb_metric_p.metric.metrics_unreduced[\"OVERALL\"][\"cmc\"][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a0357",
   "metadata": {},
   "outputs": [],
   "source": [
    "clb_metric_p = [x for x in trainer_p.callbacks if isinstance(x, MetricValCallback)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmc_1 = clb_metric.metric.metrics_unreduced[\"OVERALL\"][\"cmc\"][1]\n",
    "cmc_1_p = clb_metric_p.metric.metrics_unreduced[\"OVERALL\"][\"cmc\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-absolute",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ids = random.sample(torch.nonzero(cmc_1_p > cmc_1).squeeze().tolist(), 10)\n",
    "\n",
    "for idx in ids:\n",
    "    print(idx)\n",
    "    fig = clb_metric.metric.get_plot_for_queries([idx], n_instances=5, verbose=True)\n",
    "    plt.show()\n",
    "    fig = clb_metric_p.metric.get_plot_for_queries([idx], n_instances=5, verbose=True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-courage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c05c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from oml.models.siamese import ConcatSiamese\n",
    "from oml.models.vit.vit import ViTExtractor\n",
    "\n",
    "extractor = ViTExtractor(arch=\"vits16\", normalise_features=False, weights='/home/daloro/python_projects/open-metric-learning/embedder.ckpt')\n",
    "siamese = ConcatSiamese(extractor=extractor,\n",
    "              mlp_hidden_dims=[192],\n",
    "              weights=\"/home/daloro/python_projects/open-metric-learning/postprocessor.ckpt\"\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290f6fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 6478\n",
    "\n",
    "print(idx)\n",
    "fig = clb_metric.metric.plow_with_att([idx], extractor=extractor, siamese=siamese, prefix='embedder', save_dir='/home/daloro/paper_images', n_instances=5, verbose=True)\n",
    "plt.show()\n",
    "fig = clb_metric_p.metric.plow_with_att([idx], extractor=extractor, siamese=siamese, prefix='postprocessor', save_dir='/home/daloro/paper_images', n_instances=5, verbose=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdd3e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 14062\n",
    "\n",
    "ids_to_save = [14062, 13976, 488, 12196, 4216, 4392, 6668, 3268, 2431]\n",
    "\n",
    "for idx in ids_to_save:\n",
    "    f = clb_metric.metric.plow_with_att([idx], extractor=extractor, siamese=siamese, prefix='embedder', save_dir='/home/daloro/paper_images', n_instances=5, verbose=True);\n",
    "    f= clb_metric_p.metric.plow_with_att([idx], extractor=extractor, siamese=siamese, prefix='postprocessor', save_dir='/home/daloro/paper_images', n_instances=5, verbose=True);"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
